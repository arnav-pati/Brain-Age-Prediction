{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfNVuLK6hxWQ",
    "outputId": "fc4c6079-2a33-4288-a14b-948cf7fdf423"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uI5mtMEhKpC",
    "outputId": "36940bbe-46ec-463e-d655-8115e0cf0d16"
   },
   "outputs": [],
   "source": [
    "# !pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgQ-TOHDhXhU",
    "outputId": "c98b1213-49e6-4dbc-ee62-5a5cf09e2053"
   },
   "outputs": [],
   "source": [
    "# !pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kX7nj-8ghc9I",
    "outputId": "ed23d5d9-2bcc-4404-f408-7215763a14f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f16759c14f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################################\n",
    "#  ________   _________   ___    ___ ___  ___  ________  ________  ___  __      _______   _______\n",
    "# |\\   ___  \\|\\___   ___\\|\\  \\  /  /|\\  \\|\\  \\|\\   __  \\|\\   ____\\|\\  \\|\\  \\   /  ___  \\ /  ___  \\\n",
    "# \\ \\  \\\\ \\  \\|___ \\  \\_|\\ \\  \\/  / | \\  \\\\\\  \\ \\  \\|\\  \\ \\  \\___|\\ \\  \\/  /|_/__/|_/  //__/|_/  /|\n",
    "#  \\ \\  \\\\ \\  \\   \\ \\  \\  \\ \\    / / \\ \\   __  \\ \\   __  \\ \\  \\    \\ \\   ___  \\__|//  / /__|//  / /\n",
    "#   \\ \\  \\\\ \\  \\   \\ \\  \\  /     \\/   \\ \\  \\ \\  \\ \\  \\ \\  \\ \\  \\____\\ \\  \\\\ \\  \\  /  /_/__  /  /_/__\n",
    "#    \\ \\__\\\\ \\__\\   \\ \\__\\/  /\\   \\    \\ \\__\\ \\__\\ \\__\\ \\__\\ \\_______\\ \\__\\\\ \\__\\|\\________\\\\________\\\n",
    "#     \\|__| \\|__|    \\|__/__/ /\\ __\\    \\|__|\\|__|\\|__|\\|__|\\|_______|\\|__| \\|__| \\|_______|\\|_______|\n",
    "#                        |__|/ \\|__|\n",
    "######################################################################################################\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mne.decoding import Vectorizer\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzkDg4Sjhrsq",
    "outputId": "6a411f1b-c606-4d3a-cef8-cfbf7c01b7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V3hErMUIiGYq"
   },
   "outputs": [],
   "source": [
    "# Path to training data\n",
    "train_path = \"/home/deepak/learning_project/student/BrainAge/training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R9jQhK1_n8-Q"
   },
   "outputs": [],
   "source": [
    "# Path to testing data (public test set)\n",
    "test_path = \"/home/deepak/learning_project/student/BrainAge/testing_flat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9huk96LFoNTD"
   },
   "outputs": [],
   "source": [
    "condition_ec = \"EC\"  # closed eyes condition\n",
    "condition_eo = \"EO\"  # closed eyes condition\n",
    "train_subj = 1100  # use 1100 of the 1200 training subjects for training\n",
    "val_subj = 100   # use 100 of the 1200 training subjects for validation\n",
    "test_subj = 400  # use 10 instead of 400 testing subjects, for demonstration purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GH6upu6g3Qfx"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path, subj, ages, start):\n",
    "        self.path = path\n",
    "        self.subj = subj\n",
    "        self.ages = ages\n",
    "        self.start = start\n",
    "    def __len__(self):\n",
    "        return self.subj\n",
    "    def __getitem__(self, idx):\n",
    "        s = idx + self.start\n",
    "        fname = f\"subj{s:04}_{condition_eo}_raw.fif.gz\"\n",
    "        raw = mne.io.read_raw(self.path + fname, preload=True, verbose='warning')\n",
    "        d = raw.get_data()\n",
    "        ft = d.shape[-1]\n",
    "        data_eo = torch.zeros(1, 129, 10000)\n",
    "        data_eo[:, :, :ft] = -200 * torch.tensor(d)\n",
    "        fname = f\"subj{s:04}_{condition_ec}_raw.fif.gz\"\n",
    "        raw = mne.io.read_raw(self.path + fname, preload=True, verbose='warning')\n",
    "        d = raw.get_data()\n",
    "        ft = d.shape[-1]\n",
    "        data_ec = torch.zeros(1, 129, 20000)\n",
    "        data_ec[:, :, :ft] = -200 * torch.tensor(d)\n",
    "        data = (data_eo, data_ec)\n",
    "        age = self.ages[idx]\n",
    "        return data, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6nIDVR26HEp",
    "outputId": "97af7ff3-c770-4a1a-c14e-ca4413554179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.005932 10.356727775833333 9.587952999999999 21.899041\n"
     ]
    }
   ],
   "source": [
    "# get the age to predict from the CSV file\n",
    "meta = pd.read_csv(train_path + \"train_subjects.csv\")\n",
    "y_train = []\n",
    "for age in meta.age[:1200]:\n",
    "    y_train.append(age)\n",
    "print(np.min(y_train), np.mean(y_train), np.median(y_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dGKoWx0x7RtW"
   },
   "outputs": [],
   "source": [
    "train_data = CustomDataset(train_path, train_subj, y_train[:train_subj], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oTaTW4HK9PEH"
   },
   "outputs": [],
   "source": [
    "val_data = CustomDataset(train_path, val_subj, y_train[train_subj:train_subj+val_subj], 1 + train_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7uDN-yCC-FUW"
   },
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3iXStPhW0Pk",
    "outputId": "43330f7d-878b-40a0-f5c1-01c4da8855e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 9, 1, 1],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.ones(4,5)\n",
    "e[2,2] = 9.3\n",
    "np.around(e).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kEVFkDNr-fro"
   },
   "outputs": [],
   "source": [
    "class AgeNET(nn.Module):\n",
    "    def conv_block(self, in_channels, out_channels, kernel, stride, pool):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel, stride=stride, padding=0),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool), stride=(1, pool))\n",
    "        ).to(DEVICE)\n",
    "    def __init__(self, sampling_rate, num_T, num_C):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(DEVICE)\n",
    "        print(DEVICE)\n",
    "        self.to(DEVICE)\n",
    "        self.pool = 3\n",
    "        self.state = 0\n",
    "        self.Time1_eo = self.conv_block(1, num_T, (1, sampling_rate//2), 1, self.pool*4)\n",
    "        self.Time2_eo = self.conv_block(1, num_T, (1, sampling_rate//4), 1, self.pool*4)\n",
    "        self.Time3_eo = self.conv_block(1, num_T, (1, sampling_rate//8), 1, self.pool*4)\n",
    "        self.Time1_ec = self.conv_block(1, num_T, (1, sampling_rate//2), 1, self.pool*4)\n",
    "        self.Time2_ec = self.conv_block(1, num_T, (1, sampling_rate//4), 1, self.pool*4)\n",
    "        self.Time3_ec = self.conv_block(1, num_T, (1, sampling_rate//8), 1, self.pool*4)\n",
    "        self.BN_T_eo = nn.BatchNorm2d(num_T).to(DEVICE)\n",
    "        self.BN_T_ec = nn.BatchNorm2d(num_T).to(DEVICE)\n",
    "        self.Chan1_eo = self.conv_block(num_T, num_C, (129, 1), 1, self.pool)\n",
    "        self.Chan2_eo = self.conv_block(num_T, num_C, (65, 1), (64, 1), self.pool)\n",
    "        # self.Chan3_eo = self.conv_block(num_T, num_C, (32, 1), (32, 1), self.pool)\n",
    "        self.Chan1_ec = self.conv_block(num_T, num_C, (129, 1), 1, self.pool)\n",
    "        self.Chan2_ec = self.conv_block(num_T, num_C, (65, 1), (64, 1), self.pool)\n",
    "        # self.Chan3_ec = self.conv_block(num_T, num_C, (32, 1), (32, 1), self.pool)\n",
    "        self.BN_C_eo = nn.BatchNorm2d(num_C).to(DEVICE)\n",
    "        self.BN_C_ec = nn.BatchNorm2d(num_C).to(DEVICE)\n",
    "        size_eo, size_ec = self.get_size()\n",
    "        print(size_eo, size_ec)\n",
    "        self.fc_eo = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=size_eo, out_features=1024, bias=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_ec = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=size_ec, out_features=2048, bias=True),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=3072, out_features=1024, bias=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.01, inplace=False),\n",
    "            # nn.Linear(in_features=4096, out_features=2048, bias=True),\n",
    "            # nn.BatchNorm1d(2048),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(p=0.003, inplace=False),\n",
    "            # nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
    "            # nn.BatchNorm1d(1024),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(p=0.002, inplace=False),\n",
    "            nn.Linear(in_features=1024, out_features=512, bias=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.001, inplace=False),\n",
    "            nn.Linear(in_features=512, out_features=256, bias=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64, bias=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "#         self.last_layer = []\n",
    "#         for j in out_len:\n",
    "#             self.last_layer.append(\n",
    "#                 nn.Sequential(\n",
    "#                     nn.Linear(in_features=64, out_features=j, bias=True, device=DEVICE),\n",
    "#                     nn.ReLU()\n",
    "#                 )\n",
    "#             )\n",
    "        self.l_l0 = nn.Sequential(\n",
    "                    nn.Linear(in_features=64, out_features=25, bias=True),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "        self.l_l1 = nn.Sequential(\n",
    "                    nn.Linear(in_features=64, out_features=1, bias=True),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "    def forward(self, x_eo, x_ec):\n",
    "        y = self.Time1_eo(x_eo)\n",
    "        out_eo = y\n",
    "        y = self.Time2_eo(x_eo)\n",
    "        out_eo = torch.cat((out_eo, y), dim=-1)\n",
    "        y = self.Time3_eo(x_eo)\n",
    "        out_eo = torch.cat((out_eo, y), dim=-1)\n",
    "        y = self.Time1_ec(x_ec)\n",
    "        out_ec = y\n",
    "        y = self.Time2_ec(x_ec)\n",
    "        out_ec = torch.cat((out_ec, y), dim=-1)\n",
    "        y = self.Time3_ec(x_ec)\n",
    "        out_ec = torch.cat((out_ec, y), dim=-1)\n",
    "        out_eo = self.BN_T_eo(out_eo)\n",
    "        out_ec = self.BN_T_ec(out_ec)\n",
    "        z = self.Chan1_eo(out_eo)\n",
    "        out_f_eo = z\n",
    "        z = self.Chan2_eo(out_eo)\n",
    "        out_f_eo = torch.cat((out_f_eo, z), dim=2)\n",
    "        # z = self.Chan3_eo(out_eo)\n",
    "        # out_f_eo = torch.cat((out_f_eo, z), dim=2)\n",
    "        z = self.Chan1_ec(out_ec)\n",
    "        out_f_ec = z\n",
    "        z = self.Chan2_ec(out_ec)\n",
    "        out_f_ec = torch.cat((out_f_ec, z), dim=2)\n",
    "        # z = self.Chan3_ec(out_ec)\n",
    "        # out_f_ec = torch.cat((out_f_ec, z), dim=2)\n",
    "        out_f_eo = self.BN_C_eo(out_f_eo)\n",
    "        out_f_ec = self.BN_C_ec(out_f_ec)\n",
    "        out = torch.cat((self.fc_eo(out_f_eo), self.fc_ec(out_f_ec)), dim=-1)\n",
    "        out = self.classifier(out)\n",
    "        if self.state == 0:\n",
    "            out = self.l_l0(out)\n",
    "        else:\n",
    "            out = self.l_l1(out)\n",
    "        return out\n",
    "    def set_state(self, st):\n",
    "        self.state = st\n",
    "    def get_size(self):\n",
    "        d_eo = torch.ones(1, 1, 129, 10000).to(DEVICE)\n",
    "        d_ec = torch.ones(1, 1, 129, 20000).to(DEVICE)\n",
    "        y = self.Time1_eo(d_eo)\n",
    "        out_eo = y\n",
    "        y = self.Time2_eo(d_eo)\n",
    "        out_eo = torch.cat((out_eo, y), dim=-1)\n",
    "        y = self.Time3_eo(d_eo)\n",
    "        out_eo = torch.cat((out_eo, y), dim=-1)\n",
    "        y = self.Time1_ec(d_ec)\n",
    "        out_ec = y\n",
    "        y = self.Time2_ec(d_ec)\n",
    "        out_ec = torch.cat((out_ec, y), dim=-1)\n",
    "        y = self.Time3_ec(d_ec)\n",
    "        out_ec = torch.cat((out_ec, y), dim=-1)\n",
    "        out_eo = self.BN_T_eo(out_eo)\n",
    "        out_ec = self.BN_T_ec(out_ec)\n",
    "        z = self.Chan1_eo(out_eo)\n",
    "        out_f_eo = z\n",
    "        z = self.Chan2_eo(out_eo)\n",
    "        out_f_eo = torch.cat((out_f_eo, z), dim=2)\n",
    "        # z = self.Chan3_eo(out_eo)\n",
    "        # out_f_eo = torch.cat((out_f_eo, z), dim=2)\n",
    "        z = self.Chan1_ec(out_ec)\n",
    "        out_f_ec = z\n",
    "        z = self.Chan2_ec(out_ec)\n",
    "        out_f_ec = torch.cat((out_f_ec, z), dim=2)\n",
    "        # z = self.Chan3_ec(out_ec)\n",
    "        # out_f_ec = torch.cat((out_f_ec, z), dim=2)\n",
    "        return torch.numel(out_f_eo), torch.numel(out_f_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySNOp6gHX1JC",
    "outputId": "c1c9d247-a76c-426c-d527-f1c2a023bba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "14940 29934\n"
     ]
    }
   ],
   "source": [
    "model_A = AgeNET(128, 9, 6).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = model_A.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WathzNO-aU1x",
    "outputId": "27208844-af12-4299-c208-29757e5ed199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 9, 129, 9937]             585\n",
      "         LeakyReLU-2         [-1, 9, 129, 9937]               0\n",
      "         AvgPool2d-3          [-1, 9, 129, 828]               0\n",
      "            Conv2d-4         [-1, 9, 129, 9969]             297\n",
      "         LeakyReLU-5         [-1, 9, 129, 9969]               0\n",
      "         AvgPool2d-6          [-1, 9, 129, 830]               0\n",
      "            Conv2d-7         [-1, 9, 129, 9985]             153\n",
      "         LeakyReLU-8         [-1, 9, 129, 9985]               0\n",
      "         AvgPool2d-9          [-1, 9, 129, 832]               0\n",
      "           Conv2d-10        [-1, 9, 129, 19937]             585\n",
      "        LeakyReLU-11        [-1, 9, 129, 19937]               0\n",
      "        AvgPool2d-12         [-1, 9, 129, 1661]               0\n",
      "           Conv2d-13        [-1, 9, 129, 19969]             297\n",
      "        LeakyReLU-14        [-1, 9, 129, 19969]               0\n",
      "        AvgPool2d-15         [-1, 9, 129, 1664]               0\n",
      "           Conv2d-16        [-1, 9, 129, 19985]             153\n",
      "        LeakyReLU-17        [-1, 9, 129, 19985]               0\n",
      "        AvgPool2d-18         [-1, 9, 129, 1665]               0\n",
      "      BatchNorm2d-19         [-1, 9, 129, 2490]              18\n",
      "      BatchNorm2d-20         [-1, 9, 129, 4990]              18\n",
      "           Conv2d-21           [-1, 6, 1, 2490]           6,972\n",
      "        LeakyReLU-22           [-1, 6, 1, 2490]               0\n",
      "        AvgPool2d-23            [-1, 6, 1, 830]               0\n",
      "           Conv2d-24           [-1, 6, 2, 2490]           3,516\n",
      "        LeakyReLU-25           [-1, 6, 2, 2490]               0\n",
      "        AvgPool2d-26            [-1, 6, 2, 830]               0\n",
      "           Conv2d-27           [-1, 6, 1, 4990]           6,972\n",
      "        LeakyReLU-28           [-1, 6, 1, 4990]               0\n",
      "        AvgPool2d-29           [-1, 6, 1, 1663]               0\n",
      "           Conv2d-30           [-1, 6, 2, 4990]           3,516\n",
      "        LeakyReLU-31           [-1, 6, 2, 4990]               0\n",
      "        AvgPool2d-32           [-1, 6, 2, 1663]               0\n",
      "      BatchNorm2d-33            [-1, 6, 3, 830]              12\n",
      "      BatchNorm2d-34           [-1, 6, 3, 1663]              12\n",
      "          Flatten-35                [-1, 14940]               0\n",
      "           Linear-36                 [-1, 1024]      15,299,584\n",
      "      BatchNorm1d-37                 [-1, 1024]           2,048\n",
      "             ReLU-38                 [-1, 1024]               0\n",
      "          Flatten-39                [-1, 29934]               0\n",
      "           Linear-40                 [-1, 2048]      61,306,880\n",
      "      BatchNorm1d-41                 [-1, 2048]           4,096\n",
      "             ReLU-42                 [-1, 2048]               0\n",
      "           Linear-43                 [-1, 1024]       3,146,752\n",
      "      BatchNorm1d-44                 [-1, 1024]           2,048\n",
      "             ReLU-45                 [-1, 1024]               0\n",
      "          Dropout-46                 [-1, 1024]               0\n",
      "           Linear-47                  [-1, 512]         524,800\n",
      "      BatchNorm1d-48                  [-1, 512]           1,024\n",
      "             ReLU-49                  [-1, 512]               0\n",
      "          Dropout-50                  [-1, 512]               0\n",
      "           Linear-51                  [-1, 256]         131,328\n",
      "      BatchNorm1d-52                  [-1, 256]             512\n",
      "             ReLU-53                  [-1, 256]               0\n",
      "           Linear-54                   [-1, 64]          16,448\n",
      "      BatchNorm1d-55                   [-1, 64]             128\n",
      "             ReLU-56                   [-1, 64]               0\n",
      "           Linear-57                   [-1, 25]           1,625\n",
      "             ReLU-58                   [-1, 25]               0\n",
      "================================================================\n",
      "Total params: 80,460,379\n",
      "Trainable params: 80,460,379\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12696075.44\n",
      "Forward/backward pass size (MB): 1726.25\n",
      "Params size (MB): 306.93\n",
      "Estimated Total Size (MB): 12698108.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_A, [(1, 129, 10000), (1, 129, 20000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FXbbwFatbzuW"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, val_loader, lr, epochs):\n",
    "    train_abs_log = []\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    val_abs_log = []\n",
    "    model.train()\n",
    "    abs_loss = nn.L1Loss(reduction='mean')\n",
    "    lossfunc = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=lr)\n",
    "    f = plt.figure()\n",
    "    for epoch in range(epochs):\n",
    "        train_abs_loss = 0.0\n",
    "        train_loss = 0.0\n",
    "        print(f\"Epoch #{1 + epoch:02}: \")\n",
    "        for data, age in train_loader:\n",
    "            data_eo, data_ec = data\n",
    "            data_eo = data_eo.to(device)           # shape = (batch_size, 1, 129, 10000)\n",
    "            data_ec = data_ec.to(device)           # shape = (batch_size, 1, 129, 20000)\n",
    "            batch_size = age.size(0)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data_eo, data_ec)       # shape = (batch_size, 25)\n",
    "            loss = lossfunc(output, np.around(age).to(torch.int64).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_abs_loss += abs_loss(torch.argmax(output, dim=-1), age.to(DEVICE)).item() * batch_size\n",
    "            train_loss += loss.item() * batch_size\n",
    "        train_abs_loss /= train_subj\n",
    "        train_loss /= train_subj\n",
    "        train_abs_log.append(train_abs_loss)\n",
    "        train_log.append(train_loss)\n",
    "        val_abs_loss = 0.0\n",
    "        val_loss=0.0\n",
    "        for data, age in val_loader:\n",
    "            data_eo, data_ec = data\n",
    "            data_eo = data_eo.to(device)           # shape = (batch_size, 129, 10000)\n",
    "            data_ec = data_ec.to(device)           # shape = (batch_size, 129, 20000)\n",
    "            batch_size = age.size(0)\n",
    "            output = model(data_eo, data_ec)       # shape = (batch_size, 25)\n",
    "            loss = lossfunc(output, np.around(age).to(torch.int64).to(device))\n",
    "\n",
    "            val_abs_loss += abs_loss(torch.argmax(output, dim=-1), age.to(DEVICE)).item() * batch_size\n",
    "            val_loss += loss.item() * batch_size\n",
    "        val_abs_loss /= val_subj\n",
    "        val_loss /= val_subj\n",
    "        val_abs_log.append(val_abs_loss)\n",
    "        val_log.append(val_loss)\n",
    "        print(f\"CrossEntropyLoss:     train = {train_loss}, validation = {val_loss}\")\n",
    "        print(f\"mean absolute error:  train = {train_abs_loss}, validation = {val_abs_loss}\")\n",
    "        plt.clf()\n",
    "        plt.plot(train_log, label='train loss')\n",
    "        plt.plot(val_log, label='validation loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return train_abs_log, val_abs_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YhuPAGVLmsq",
    "outputId": "4de1370f-c3fb-4ff6-eb8e-37a302fecb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #01: \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.38 GiB (GPU 0; 23.70 GiB total capacity; 21.17 GiB already allocated; 20.12 MiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_abs_log, val_abs_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.008\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [24], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, val_loader, lr, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m data_ec \u001b[38;5;241m=\u001b[39m data_ec\u001b[38;5;241m.\u001b[39mto(device)           \u001b[38;5;66;03m# shape = (batch_size, 129, 20000)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m age\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_eo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_ec\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# shape = (batch_size, 25)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m lossfunc(output, np\u001b[38;5;241m.\u001b[39maround(age)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     42\u001b[0m val_abs_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m abs_loss(torch\u001b[38;5;241m.\u001b[39margmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), age\u001b[38;5;241m.\u001b[39mto(DEVICE))\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_size\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [15], line 92\u001b[0m, in \u001b[0;36mAgeNET.forward\u001b[0;34m(self, x_eo, x_ec)\u001b[0m\n\u001b[1;32m     90\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTime3_eo(x_eo)\n\u001b[1;32m     91\u001b[0m out_eo \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((out_eo, y), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTime1_ec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m out_ec \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m     94\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTime2_ec(x_ec)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.38 GiB (GPU 0; 23.70 GiB total capacity; 21.17 GiB already allocated; 20.12 MiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_abs_log, val_abs_log = train(model_A, DEVICE, train_loader, val_loader, 0.008, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
